{% disable_client_cache %}

<style>
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
        }
        code {
            color: #d63384;
            font-family: Consolas, Monaco, "Andale Mono", "Ubuntu Mono", monospace;
        }
    </style>

<h1>APIs Usage Examples</h1>

<h2>Text Generation (Mistral, Granite,...)</h2>
<h3>Using Curl</h3>
<pre>
<code>
curl -X 'POST' \
    'https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1/completions' \
    -H 'accept: application/json' \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer ***************************' \
    -d '{
    "model": "granite-8b-code-instruct-128k",
    "prompt": "San Francisco is a",
    "max_tokens": 15,
    "temperature": 0
}'
</code>
</pre>

<h3>Using raw Python</h3>
<pre>
<code>
import requests
import urllib3
import numpy as np
import json

API_URL = "https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443"
API_KEY = "***************************"

input = ["San Francisco is a"]

completion = requests.post(
    url=API_URL+'/v1/completions',
    json={
      "model": "granite-8b-code-instruct-128k",
      "prompt": "San Francisco is a",
      "max_tokens": 15,
      "temperature": 0
    },
    headers={'Authorization': 'Bearer '+API_KEY}
).json()

print(completion)
</code>
</pre>

<h3>Using Langchain</h3>
Prerequisites: <code>pip install langchain-community</code>
<pre>
<code>
from langchain_community.llms import VLLMOpenAI

API_URL = "https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443"
API_KEY = "***************************"

llm = VLLMOpenAI(
    openai_api_key=API_KEY,
    openai_api_base=API_URL+"/v1",
    model_name="granite-8b-code-instruct-128k",
    model_kwargs={"stop": ["."]},
)
print(llm.invoke("Rome is"))
</code>
</pre>

<h3>Connecting Continue.dev to Granite-Code-Instruct</h3>
Configuration in <code>.continue/config.json</code>
<pre>
<code>
...
  "models": [
    {
      "title": "Granite-8B-Instruct",
      "provider": "openai",
      "model": "granite-8b-code-instruct-128k",
      "apiBase": "https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1/",
      "apiKey": "************************",
      "completionOptions": {
        "temperature": 0.1,
        "topK": 1,
        "topP": 1,
        "presencePenalty": 0,
        "frequencyPenalty": 0
      }
    }
  ]
...
  "tabAutocompleteModel": {
    "title": "Granite-8B-Instruct",
    "provider": "openai",
    "model": "granite-8b-code-instruct-128k",
    "apiBase": "https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1/",
    "apiKey": "****************************",
    "completionOptions": {
      "temperature": 0.1,
      "topK": 1,
      "topP": 1,
      "presencePenalty": 0,
      "frequencyPenalty": 0
    }
  },
  "tabAutocompleteOptions": {
    "useCopyBuffer": false,
    "maxPromptTokens": 1024,
    "prefixPercentage": 0.5
  },
...
</code>
</pre>


<h2>Embeddings (Nomic-Embed-Text,...)</h2>
<h3>Using Curl</h3>
<pre>
<code>
curl -X 'POST' \
  'https://nomic-embed-text-v1-5-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/embed' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer *************************' \
  -d '{
  "inputs": "string",
  "normalize": true,
  "truncate": false,
  "truncation_direction": "Right"
}'
</code>
</pre>
<h3>Using raw Python</h3>
<pre>
<code>
# Calling the base embeddings API

import requests
import urllib3
import numpy as np
import json

API_URL = "https://nomic-embed-text-v1-5-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443"
API_KEY = "*************************"

test_strings = ["That is a happy dog","That is a very happy person","Today is a sunny day"]

embeddings = requests.post(
    url=API_URL+'/embed',
    json={"inputs": test_strings},
    headers={'Authorization': 'Bearer '+API_KEY}
).json()

print(embeddings)
</code>
</pre>

<pre>
<code>
# Calling the OpenAI-compatible embeddings API

import requests
import urllib3
import numpy as np
import json

API_URL = "https://nomic-embed-text-v1-5-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443"
API_KEY = "*************************"

test_strings = ["That is a happy dog","That is a very happy person","Today is a sunny day"]

embeddings = requests.post(
    url=API_URL+'/v1/embeddings',
    json={"input": test_strings},
    headers={'Authorization': 'Bearer '+API_KEY}
).json()

print(embeddings)
</code>
</pre>
<h3>Using Langchain</h3>

Prerequisites: <code>pip install langchain-openai</code>
<pre>
<code>
from langchain_openai import OpenAIEmbeddings

API_URL = "https://nomic-embed-text-v1-5-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443"
API_KEY = "*************************"

embeddings_model = OpenAIEmbeddings(openai_api_base=API_URL, openai_api_key=API_KEY)

test_strings = ["That is a happy dog","That is a very happy person","Today is a sunny day"]

embeddings = embeddings_model.embed_documents(test_strings)

print(embeddings)
    </code>
</pre>

<h3>Connecting Continue.dev to Nomic-Embed-Text</h3>
Configuration in <code>.continue/config.json</code>
<pre>
<code>
...
  "embeddingsProvider": {
    "title": "Nomic-embed-text-v1.5",
    "provider": "openai",
    "model": "nomic-embed-text-v1.5",
    "apiBase": "https://nomic-embed-text-v1-5-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1/",
    "apiKey": "*************************",
    "maxBatchSize": 32
  },
...
</code>
</pre>
